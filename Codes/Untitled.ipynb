{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DataManager, VerificationDataset, OneshotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALPHABET IN BACKGROUND : 30\n",
      "\t ['Alphabet_of_the_Magi', 'Anglo-Saxon_Futhorc', 'Arcadian', 'Armenian', 'Asomtavruli_(Georgian)']\n",
      "ALPHABET IN VALIDATION : 10\n",
      "\t ['Atemayar_Qelisayer', 'Glagolitic', 'Aurek-Besh', 'Oriya', 'Syriac_(Serto)']\n",
      "ALPHABET IN EVALUATION : 10\n",
      "\t ['Angelic', 'Avesta', 'Ge_ez', 'Keble', 'Malayalam']\n",
      "TRAIN DRAWERS: ['01', '02', '03', '04', '05', '08', '11', '14', '16', '17', '18', '19']\n",
      "VALID DRAWERS: ['06', '07', '09', '20']\n",
      "TEST DRAWERS: ['10', '12', '13', '15']\n"
     ]
    }
   ],
   "source": [
    "bg_dir = \"../data/python/images_background/images_background/\"\n",
    "eval_dir = \"../data/python/images_evaluation/images_evaluation/\"\n",
    "seed = 10\n",
    "dm = DataManager(bg_dir = bg_dir, eval_dir = eval_dir, seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 10000 th pair was generated:\n",
      "\t ..\\data\\python\\images_background\\images_background\\Braille\\character01\\0192_04.png Braille Braille_character01\n",
      "\t ..\\data\\python\\images_background\\images_background\\Korean\\character22\\0664_11.png Korean Korean_character22\n",
      "\t 20000 th pair was generated:\n",
      "\t ..\\data\\python\\images_background\\images_background\\Armenian\\character33\\0059_08.png Armenian Armenian_character33\n",
      "\t ..\\data\\python\\images_background\\images_background\\Mkhedruli_(Georgian)\\character18\\0746_16.png Mkhedruli_(Georgian) Mkhedruli_(Georgian)_character18\n",
      "\t 30000 th pair was generated:\n",
      "\t ..\\data\\python\\images_background\\images_background\\Ojibwe_(Canadian_Aboriginal_Syllabics)\\character13\\0849_01.png Ojibwe_(Canadian_Aboriginal_Syllabics) Ojibwe_(Canadian_Aboriginal_Syllabics)_character13\n",
      "\t ..\\data\\python\\images_background\\images_background\\Ojibwe_(Canadian_Aboriginal_Syllabics)\\character08\\0844_11.png Ojibwe_(Canadian_Aboriginal_Syllabics) Ojibwe_(Canadian_Aboriginal_Syllabics)_character08\n",
      "=================================\n",
      "STATISTICS OF GENERATED EXAMPLES:\n",
      "\tTOTAL EXAMPLE: 30000\n",
      "\t Alphabet_of_the_Magi : 2000\n",
      "\t Anglo-Saxon_Futhorc : 2000\n",
      "\t Arcadian : 2000\n",
      "\t Armenian : 2000\n",
      "\t Asomtavruli_(Georgian) : 2000\n",
      "\t Balinese : 2000\n",
      "\t Bengali : 2000\n",
      "\t Blackfoot_(Canadian_Aboriginal_Syllabics) : 2000\n",
      "\t Braille : 2000\n",
      "\t Burmese_(Myanmar) : 2000\n",
      "\t Cyrillic : 2000\n",
      "\t Early_Aramaic : 2000\n",
      "\t Futurama : 2000\n",
      "\t Grantha : 2000\n",
      "\t Greek : 2000\n",
      "\t Gujarati : 2000\n",
      "\t Hebrew : 2000\n",
      "\t Inuktitut_(Canadian_Aboriginal_Syllabics) : 2001\n",
      "\t Japanese_(hiragana) : 2000\n",
      "\t Japanese_(katakana) : 2000\n",
      "\t Korean : 2000\n",
      "\t Latin : 2000\n",
      "\t Malay_(Jawi_-_Arabic) : 2000\n",
      "\t Mkhedruli_(Georgian) : 2000\n",
      "\t N_Ko : 2000\n",
      "\t Ojibwe_(Canadian_Aboriginal_Syllabics) : 1997\n",
      "\t Sanskrit : 2000\n",
      "\t Syriac_(Estrangelo) : 2001\n",
      "\t Tagalog : 2001\n",
      "\t Tifinagh : 2000\n",
      "\t CNT OF SAME CLASS: 62\n"
     ]
    }
   ],
   "source": [
    "train_vd = VerificationDataset(path_dict = dm.bg_paths, drawers = dm.train_drawers, sample_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p = train_vd.data_pairs[0]\n",
    "from skimage import io\n",
    "print(d_p[0])\n",
    "im = io.imread(d_p[0])\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(p) for p in d_p[:2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(d_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "t = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t(im).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = 6\n",
    "for i in range(1, rows*2, 2):\n",
    "    img1, img2, label = train_vd[int((i-1)/2)]\n",
    "    print(img1.shape, img2.shape)\n",
    "    ax = plt.subplot(rows, 2, i)\n",
    "    ax = plt.imshow(transforms.ToPILImage()(img1))\n",
    "    ax = plt.subplot(rows, 2, i+1)\n",
    "    ax = plt.imshow(transforms.ToPILImage()(img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
